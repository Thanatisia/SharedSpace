# Computer Science: Big-O Notation

## Basics
- When you are talking about the 'Big-O' Notation in Computer Science, you are usually referring to the Time complexity of a Data Structure and Algorithm (DSA).
    + Basically, the time it takes to run, or the amount of memory it uses, given larger inputs
    + As the size of the input gets bigger, the time of the worst case will get longer, and the amount of memory the algorithm takes will become bigger.

## O-notation time-action equivalents
+ O(1)          = Constant time    = Array Lookup
+ O(log<n>)     = Logarithmic time = Binary search
+ O(n)          = Linear time      = Find in unsorted array
+ O(n * log<n>) = Quasilinear time = Comparison sorts (i.e. Merge sort etc)
+ O(n^2)        = Quadratic time   = Bubble sort

## Wiki

## Resources
+ [Wikipedia - Big O Notation](en.wikipedia.org/wiki/Big_O_notation)
+ [Wikipedia - Time complexity](en.wikipedia.org/wiki/Time_complexity)

## References
+ [YouTube - SimonDev - What Big-O notation ACTUALLY tells you, and how I almost failed my Google Interview](youtube.com/watch?v=gCzOhZ_LUps)

## Remarks